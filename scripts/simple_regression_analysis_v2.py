#!/usr/bin/env python3
"""
ç®€å•å›å½’åˆ†æ - ä¸generate_graphs_simple.pyä¿æŒä¸€è‡´çš„æ–¹æ³•
ä»…ä½¿ç”¨Linearå’ŒPolynomialå›å½’æ¨¡å‹ï¼Œé¿å…è¿‡æ‹Ÿåˆé—®é¢˜
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import cross_val_score, LeaveOneOut
from sklearn.pipeline import Pipeline
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

def fit_simple_models(x, y):
    """è®­ç»ƒLinearå’ŒPolynomialå›å½’æ¨¡å‹å¹¶è¿”å›æœ€ä½³æ¨¡å‹çš„ç»“æœï¼ˆä¸generate_graphs_simple.pyä¿æŒä¸€è‡´ï¼‰"""
    try:
        # ç§»é™¤NaNå€¼
        mask = ~(np.isnan(x) | np.isnan(y))
        x_clean = x[mask]
        y_clean = y[mask]
        
        if len(x_clean) < 5:
            return None, "insufficient_data", {}
        
        # é‡å¡‘æ•°æ®ä¸ºsklearnæ ¼å¼
        X = x_clean.reshape(-1, 1)
        
        # å®šä¹‰ä¸¤ä¸ªå›å½’æ¨¡å‹
        models = {
            'Linear': LinearRegression(),
            'Polynomial': LinearRegression()  # å°†ä¸å¤šé¡¹å¼ç‰¹å¾ä¸€èµ·ä½¿ç”¨
        }
        
        model_results = {}
        best_model = None
        best_r2 = -np.inf
        best_model_name = ""
        
        for name, model in models.items():
            try:
                if name == 'Polynomial':
                    # å¤šé¡¹å¼å›å½’
                    poly_features = PolynomialFeatures(degree=2)
                    X_poly = poly_features.fit_transform(X)
                    model.fit(X_poly, y_clean)
                    y_pred = model.predict(X_poly)
                    
                    # ç”¨äºäº¤å‰éªŒè¯çš„å¤šé¡¹å¼ç®¡é“
                    poly_pipeline = Pipeline([
                        ('poly', PolynomialFeatures(degree=2)),
                        ('linear', LinearRegression())
                    ])
                    cv_model = poly_pipeline
                else:
                    # çº¿æ€§å›å½’
                    model.fit(X, y_clean)
                    y_pred = model.predict(X)
                    cv_model = model
                
                # è®¡ç®—è®­ç»ƒRÂ²
                r2 = r2_score(y_clean, y_pred)
                mse = mean_squared_error(y_clean, y_pred)
                
                # äº¤å‰éªŒè¯
                try:
                    cv_scores = cross_val_score(cv_model, X, y_clean, 
                                              cv=LeaveOneOut(), scoring='r2')
                    cv_scores = cv_scores[~np.isnan(cv_scores) & ~np.isinf(cv_scores)]
                    cv_r2 = cv_scores.mean() if len(cv_scores) > 0 else 0.0
                    cv_std = cv_scores.std() if len(cv_scores) > 0 else 0.0
                except Exception as e:
                    cv_r2 = 0.0
                    cv_std = 0.0
                    cv_scores = np.array([0.0])
                
                # è®¡ç®—çš®å°”é€Šç›¸å…³ç³»æ•°
                correlation, p_value = stats.pearsonr(x_clean, y_clean)
                
                model_results[name] = {
                    'r2': r2,
                    'cv_r2': cv_r2,
                    'cv_std': cv_std,
                    'cv_scores': cv_scores,
                    'overfitting': r2 - cv_r2,
                    'mse': mse,
                    'correlation': correlation,
                    'p_value': p_value,
                    'model': model
                }
                
                # æ›´æ–°æœ€ä½³æ¨¡å‹ï¼ˆä½¿ç”¨è®­ç»ƒRÂ²ä½œä¸ºæ ‡å‡†ï¼Œä¸generate_graphs_simple.pyä¸€è‡´ï¼‰
                if r2 > best_r2:
                    best_r2 = r2
                    best_model = name
                    best_model_name = name
                    
            except Exception as e:
                print(f"   âš ï¸ æ¨¡å‹ {name} è®­ç»ƒå¤±è´¥: {e}")
                continue
        
        if best_model is None:
            return None, "no_valid_model", {}
        
        return model_results, best_model_name, model_results[best_model]
        
    except Exception as e:
        print(f"âš ï¸ æ¨¡å‹æ‹Ÿåˆå¤±è´¥: {e}")
        return None, "error", {}

def analyze_relationship(x, y, feature_name, target_name):
    """åˆ†æä¸¤ä¸ªå˜é‡ä¹‹é—´çš„å…³ç³»ï¼Œä½¿ç”¨Linearå’ŒPolynomialå›å½’ï¼ˆä¸generate_graphs_simple.pyä¿æŒä¸€è‡´ï¼‰"""
    
    # ç§»é™¤NaNå€¼
    mask = ~(np.isnan(x) | np.isnan(y))
    x_clean = x[mask]
    y_clean = y[mask]
    
    if len(x_clean) < 5:
        return None
    
    print(f"\nğŸ“Š åˆ†æ: {feature_name} vs {target_name}")
    print(f"   æ ·æœ¬æ•°é‡: {len(x_clean)}")
    
    # 1. çš®å°”é€Šç›¸å…³ç³»æ•°
    pearson_r, pearson_p = stats.pearsonr(x_clean, y_clean)
    print(f"   çš®å°”é€Šç›¸å…³ç³»æ•°: r = {pearson_r:.4f}, p-value = {pearson_p:.4f}")
    
    # 2. ä½¿ç”¨ä¸generate_graphs_simple.pyç›¸åŒçš„æ¨¡å‹æ‹Ÿåˆæ–¹å¼
    model_results, best_model_name, best_result = fit_simple_models(x, y)
    
    if model_results is None:
        print(f"   âš ï¸ æ¨¡å‹æ‹Ÿåˆå¤±è´¥")
        return None
    
    # è¾“å‡ºå„æ¨¡å‹ç»“æœ
    for name, result in model_results.items():
        print(f"   {name}å›å½’:")
        print(f"     è®­ç»ƒ RÂ²: {result['r2']:.4f}")
        print(f"     äº¤å‰éªŒè¯ RÂ²: {result['cv_r2']:.4f} Â± {result['cv_std']:.4f}")
        print(f"     è¿‡æ‹Ÿåˆç¨‹åº¦: {result['overfitting']:.4f}")
    
    # 3. æ•°æ®ç‰¹å¾åˆ†æ
    x_range = x_clean.max() - x_clean.min()
    x_cv = np.std(x_clean) / np.mean(x_clean) if np.mean(x_clean) != 0 else 0
    y_range = y_clean.max() - y_clean.min()
    y_cv = np.std(y_clean) / np.mean(y_clean) if np.mean(y_clean) != 0 else 0
    
    print(f"   æ•°æ®ç‰¹å¾:")
    print(f"     Xå˜å¼‚ç³»æ•°: {x_cv:.4f}")
    print(f"     Yå˜å¼‚ç³»æ•°: {y_cv:.4f}")
    print(f"     XèŒƒå›´/å‡å€¼: {x_range/np.mean(x_clean):.4f}" if np.mean(x_clean) != 0 else "     XèŒƒå›´/å‡å€¼: N/A")
    print(f"     YèŒƒå›´/å‡å€¼: {y_range/np.mean(y_clean):.4f}" if np.mean(y_clean) != 0 else "     YèŒƒå›´/å‡å€¼: N/A")
    
    # 4. è´¨é‡è¯„ä¼°ï¼ˆåŸºäºæœ€ä½³æ¨¡å‹ï¼‰
    best_r2 = best_result['r2']
    best_cv_r2 = best_result['cv_r2']
    best_overfitting = best_result['overfitting']
    
    if abs(pearson_r) < 0.2:
        quality = "å¼±ç›¸å…³"
    elif best_overfitting > 0.3:
        quality = "è¿‡æ‹Ÿåˆä¸¥é‡"
    elif best_cv_r2 < 0.1:
        quality = "æ¨¡å‹æ•ˆæœå·®"
    elif best_cv_r2 > 0.3 and best_overfitting < 0.1:
        quality = "è‰¯å¥½"
    else:
        quality = "ä¸€èˆ¬"
    
    print(f"   æœ€ä½³æ¨¡å‹: {best_model_name}")
    print(f"   æ¨¡å‹è´¨é‡: {quality}")
    
    return {
        'feature': feature_name,
        'target': target_name,
        'sample_size': len(x_clean),
        'pearson_r': pearson_r,
        'pearson_p': pearson_p,
        'linear_train_r2': model_results['Linear']['r2'],
        'linear_cv_r2': model_results['Linear']['cv_r2'],
        'linear_overfitting': model_results['Linear']['overfitting'],
        'polynomial_train_r2': model_results['Polynomial']['r2'],
        'polynomial_cv_r2': model_results['Polynomial']['cv_r2'],
        'polynomial_overfitting': model_results['Polynomial']['overfitting'],
        'best_model': best_model_name,
        'best_train_r2': best_r2,
        'best_cv_r2': best_cv_r2,
        'best_overfitting': best_overfitting,
        'quality': quality,
        'x_cv': x_cv,
        'y_cv': y_cv
    }

def create_diagnostic_plot(df, x_col, y_col, output_dir):
    """åˆ›å»ºè¯Šæ–­å›¾è¡¨"""
    
    x = df[x_col].values
    y = df[y_col].values
    
    # ç§»é™¤NaNå€¼
    mask = ~(np.isnan(x) | np.isnan(y))
    x_clean = x[mask]
    y_clean = y[mask]
    
    if len(x_clean) < 5:
        return None
    
    # åˆ›å»ºå›¾å½¢
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
    
    # 1. åŸå§‹æ•£ç‚¹å›¾ + æœ€ä½³å›å½’çº¿
    ax1.scatter(x_clean, y_clean, alpha=0.7, s=60, color='steelblue', edgecolors='black')
    
    # ä½¿ç”¨ä¸generate_graphs_simple.pyç›¸åŒçš„æ‹Ÿåˆæ–¹æ³•
    model_results, best_model_name, best_result = fit_simple_models(x, y)
    
    if model_results is not None:
        # ç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿
        X = x_clean.reshape(-1, 1)
        if best_model_name == 'Polynomial':
            poly_features = PolynomialFeatures(degree=2)
            X_poly = poly_features.fit_transform(X)
            x_line = np.linspace(x_clean.min(), x_clean.max(), 100).reshape(-1, 1)
            X_line_poly = poly_features.transform(x_line)
            y_line = best_result['model'].predict(X_line_poly)
        else:
            x_line = np.linspace(x_clean.min(), x_clean.max(), 100).reshape(-1, 1)
            y_line = best_result['model'].predict(x_line)
        
        color = 'red' if best_model_name == 'Polynomial' else 'darkred'
        ax1.plot(x_line, y_line, color=color, linewidth=2, 
                label=f'{best_model_name} (RÂ² = {best_result["r2"]:.3f})')
    
    ax1.set_title(f'{x_col} vs {y_col}')
    ax1.set_xlabel(x_col)
    ax1.set_ylabel(y_col)
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
    if model_results is not None:
        stats_text = f'è®­ç»ƒRÂ²: {best_result["r2"]:.3f}\näº¤å‰éªŒè¯RÂ²: {best_result["cv_r2"]:.3f}\nçš®å°”é€Šr: {best_result["correlation"]:.3f}'
        ax1.text(0.05, 0.95, stats_text, transform=ax1.transAxes, 
                 verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))
    
    # 2. æ®‹å·®å›¾
    if model_results is not None:
        X = x_clean.reshape(-1, 1)
        if best_model_name == 'Polynomial':
            poly_features = PolynomialFeatures(degree=2)
            X_poly = poly_features.fit_transform(X)
            y_pred = best_result['model'].predict(X_poly)
        else:
            y_pred = best_result['model'].predict(X)
        
        residuals = y_clean - y_pred
        ax2.scatter(y_pred, residuals, alpha=0.7, s=60, color='green')
        ax2.axhline(y=0, color='red', linestyle='--')
        ax2.set_title('æ®‹å·®å›¾')
        ax2.set_xlabel('é¢„æµ‹å€¼')
        ax2.set_ylabel('æ®‹å·®')
        ax2.grid(True, alpha=0.3)
        
        # 3. Q-Qå›¾æ£€éªŒæ®‹å·®æ­£æ€æ€§
        stats.probplot(residuals, dist="norm", plot=ax3)
        ax3.set_title('æ®‹å·®Q-Qå›¾')
        ax3.grid(True, alpha=0.3)
        
        # 4. äº¤å‰éªŒè¯åˆ†æ•°åˆ†å¸ƒ
        cv_scores = best_result['cv_scores']
        cv_r2 = best_result['cv_r2']
        
        # æ£€æŸ¥å¹¶æ¸…ç†cv_scoresæ•°æ®
        cv_scores_clean = cv_scores[~np.isnan(cv_scores) & ~np.isinf(cv_scores)]
        
        if len(cv_scores_clean) > 0 and np.std(cv_scores_clean) > 1e-10:
            # åŠ¨æ€ç¡®å®šbinsæ•°é‡
            n_bins = min(10, max(3, len(cv_scores_clean) // 2))
            ax4.hist(cv_scores_clean, bins=n_bins, alpha=0.7, color='orange', edgecolor='black')
            ax4.axvline(cv_r2, color='red', linestyle='--', linewidth=2, label=f'å¹³å‡: {cv_r2:.3f}')
            ax4.set_title('äº¤å‰éªŒè¯RÂ²åˆ†å¸ƒ')
            ax4.set_xlabel('RÂ²')
            ax4.set_ylabel('é¢‘æ¬¡')
            ax4.legend()
        else:
            # å¦‚æœæ•°æ®æ— æ•ˆï¼Œæ˜¾ç¤ºæ–‡æœ¬è¯´æ˜
            ax4.text(0.5, 0.5, f'äº¤å‰éªŒè¯æ•°æ®:\nå¹³å‡RÂ²: {cv_r2:.3f}\næ ·æœ¬æ•°: {len(cv_scores)}', 
                    ha='center', va='center', transform=ax4.transAxes,
                    bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))
            ax4.set_title('äº¤å‰éªŒè¯RÂ²ä¿¡æ¯')
            ax4.set_xlim(0, 1)
            ax4.set_ylim(0, 1)
        
        ax4.grid(True, alpha=0.3)
    else:
        # å¦‚æœæ¨¡å‹æ‹Ÿåˆå¤±è´¥ï¼Œæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
        for ax in [ax2, ax3, ax4]:
            ax.text(0.5, 0.5, 'æ¨¡å‹æ‹Ÿåˆå¤±è´¥', ha='center', va='center', transform=ax.transAxes)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡
    filename = f"{x_col}_{y_col}_diagnostic.png"
    filepath = os.path.join(output_dir, filename)
    plt.savefig(filepath, dpi=200, bbox_inches='tight')
    plt.close()
    
    return filepath

def main():
    print("ğŸ” å¼€å§‹ç®€å•å›å½’åˆ†æ - ä¸generate_graphs_simple.pyä¿æŒä¸€è‡´çš„æ–¹æ³•")
    
    # è®¾ç½®è·¯å¾„
    data_file = "/home/ubuntu/project/MSC/Msc_Project/models/input_1-100/merged_dataset.csv"
    output_dir = "/home/ubuntu/project/MSC/Msc_Project/models/analysis_simple_v2"
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    print(f"ğŸ“Š æ•°æ®æ–‡ä»¶: {data_file}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # åŠ è½½æ•°æ®
    try:
        df = pd.read_csv(data_file)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return 1
    
    # å®šä¹‰ç‰¹å¾å’Œç›®æ ‡å˜é‡
    layout_features = [
        'avg_dist_to_center', 'std_pairwise_distance', 'min_pairwise_distance',
        'max_pairwise_distance', 'cs_density_std', 'cluster_count',
        'coverage_ratio', 'max_gap_distance', 'gini_coefficient',
        'avg_betweenness_centrality'
    ]
    
    performance_metrics = [
        'duration_mean', 'waiting_time_mean', 'charging_time_mean',
        'energy_gini', 'vehicle_gini', 'charging_station_coverage',
        'reroute_count', 'ev_charging_participation_rate'
    ]
    
    print(f"ğŸ“Š å¸ƒå±€ç‰¹å¾: {len(layout_features)} ä¸ª")
    print(f"ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡: {len(performance_metrics)} ä¸ª")
    print(f"ğŸ’¡ ä½¿ç”¨Linearå’ŒPolynomialå›å½’æ¨¡å‹ï¼ˆä¸generate_graphs_simple.pyä¸€è‡´ï¼‰")
    
    # åˆ†ææ‰€æœ‰ç»„åˆ
    results = []
    
    print(f"\nğŸ” å¼€å§‹åˆ†æ {len(layout_features) * len(performance_metrics)} ä¸ªç»„åˆ...")
    
    for i, feature in enumerate(layout_features):
        print(f"\n[{i+1}/{len(layout_features)}] å¤„ç†ç‰¹å¾: {feature}")
        
        for j, target in enumerate(performance_metrics):
            if feature in df.columns and target in df.columns:
                # åˆ†æå…³ç³»
                result = analyze_relationship(
                    df[feature].values, 
                    df[target].values, 
                    feature, 
                    target
                )
                
                if result:
                    results.append(result)
                    
                    # ä¸ºè´¨é‡å¥½çš„å…³ç³»åˆ›å»ºè¯Šæ–­å›¾
                    if result['quality'] in ['è‰¯å¥½', 'ä¸€èˆ¬'] and abs(result['pearson_r']) > 0.15:
                        print(f"     åˆ›å»ºè¯Šæ–­å›¾...")
                        create_diagnostic_plot(df, feature, target, output_dir)
    
    # ä¿å­˜ç»“æœ
    if results:
        results_df = pd.DataFrame(results)
        results_file = os.path.join(output_dir, "regression_analysis_results_v2.csv")
        results_df.to_csv(results_file, index=False)
        
        print(f"\nğŸ‰ åˆ†æå®Œæˆï¼")
        print(f"ğŸ“Š æ€»å…±åˆ†æ: {len(results)} ä¸ªå…³ç³»")
        print(f"ğŸ’¾ ç»“æœä¿å­˜åˆ°: {results_file}")
        
        # æ±‡æ€»ç»Ÿè®¡
        print(f"\nğŸ“ˆ è´¨é‡åˆ†å¸ƒ:")
        quality_counts = results_df['quality'].value_counts()
        for quality, count in quality_counts.items():
            print(f"   {quality}: {count} ä¸ª")
        
        print(f"\nğŸ† æœ€ä½³å…³ç³» (æŒ‰è®­ç»ƒRÂ²æ’åº):")
        best_results = results_df.sort_values('best_train_r2', ascending=False).head(10)
        for _, row in best_results.iterrows():
            print(f"   {row['feature']} -> {row['target']}: "
                  f"è®­ç»ƒ RÂ² = {row['best_train_r2']:.4f}, "
                  f"CV RÂ² = {row['best_cv_r2']:.4f}, "
                  f"è¿‡æ‹Ÿåˆ = {row['best_overfitting']:.4f}, "
                  f"æ¨¡å‹ = {row['best_model']}, "
                  f"è´¨é‡ = {row['quality']}")
        
        print(f"\nğŸ“Š æ¨¡å‹åˆ†å¸ƒ:")
        model_counts = results_df['best_model'].value_counts()
        for model, count in model_counts.items():
            print(f"   {model}: {count} ä¸ª")
        
        print(f"\nâš ï¸ è¿‡æ‹Ÿåˆä¸¥é‡çš„å…³ç³»:")
        overfitting_issues = results_df[results_df['best_overfitting'] > 0.2]
        if len(overfitting_issues) > 0:
            for _, row in overfitting_issues.iterrows():
                print(f"   {row['feature']} -> {row['target']}: "
                      f"è¿‡æ‹Ÿåˆ = {row['best_overfitting']:.4f}, æ¨¡å‹ = {row['best_model']}")
        else:
            print(f"   âœ… æ²¡æœ‰ä¸¥é‡è¿‡æ‹Ÿåˆçš„å…³ç³»")
        
        print(f"\nğŸ“Š å»ºè®®:")
        good_quality = len(results_df[results_df['quality'] == 'è‰¯å¥½'])
        if good_quality > 0:
            print(f"   âœ… å‘ç° {good_quality} ä¸ªé«˜è´¨é‡å…³ç³»ï¼Œå¯ç”¨äºè®ºæ–‡")
        else:
            moderate_quality = len(results_df[results_df['quality'] == 'ä¸€èˆ¬'])
            print(f"   ğŸ“Š å‘ç° {moderate_quality} ä¸ªä¸­ç­‰è´¨é‡å…³ç³»")
            print(f"   ğŸ’¡ å»ºè®®è€ƒè™‘æ•°æ®æ’å€¼ä»¥æ”¹å–„æ¨¡å‹æ³›åŒ–èƒ½åŠ›")
    
    return 0

if __name__ == '__main__':
    exit(main())
