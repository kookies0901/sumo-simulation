#!/usr/bin/env python3
"""
è¿‡æ‹Ÿåˆç°è±¡è§£é‡Š - ä¸ºä»€ä¹ˆé«˜RÂ²å¯èƒ½æ˜¯é—®é¢˜
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import r2_score
from sklearn.model_selection import cross_val_score, LeaveOneOut

def demonstrate_overfitting():
    """æ¼”ç¤ºè¿‡æ‹Ÿåˆç°è±¡"""
    
    # 1. ç”ŸæˆçœŸå®çš„ç®€å•å…³ç³»æ•°æ®
    np.random.seed(42)
    n_samples = 20  # å°æ ·æœ¬ï¼Œç±»ä¼¼æ‚¨çš„æ•°æ®
    X_true = np.linspace(0, 10, n_samples)
    
    # çœŸå®å…³ç³»ï¼šç®€å•çº¿æ€§å…³ç³» + å°‘é‡å™ªå£°
    y_true = 2 * X_true + 3 + np.random.normal(0, 2, n_samples)
    
    X_true = X_true.reshape(-1, 1)
    
    print("ğŸ” è¿‡æ‹Ÿåˆç°è±¡æ¼”ç¤º")
    print(f"æ ·æœ¬æ•°é‡: {n_samples}")
    print("çœŸå®å…³ç³»: y = 2x + 3 + å™ªå£°")
    
    # 2. æ¯”è¾ƒä¸åŒå¤æ‚åº¦çš„æ¨¡å‹
    models = {
        'çº¿æ€§å›å½’': (PolynomialFeatures(1), 'blue'),
        '2æ¬¡å¤šé¡¹å¼': (PolynomialFeatures(2), 'red'),
        '5æ¬¡å¤šé¡¹å¼': (PolynomialFeatures(5), 'green'),
        '10æ¬¡å¤šé¡¹å¼': (PolynomialFeatures(10), 'purple')
    }
    
    plt.figure(figsize=(15, 10))
    
    for i, (name, (poly, color)) in enumerate(models.items(), 1):
        plt.subplot(2, 2, i)
        
        # è½¬æ¢ç‰¹å¾
        X_poly = poly.fit_transform(X_true)
        
        # è®­ç»ƒæ¨¡å‹
        model = LinearRegression()
        model.fit(X_poly, y_true)
        
        # è®­ç»ƒRÂ²
        y_pred_train = model.predict(X_poly)
        train_r2 = r2_score(y_true, y_pred_train)
        
        # äº¤å‰éªŒè¯RÂ²
        from sklearn.pipeline import Pipeline
        pipeline = Pipeline([('poly', poly), ('linear', LinearRegression())])
        cv_scores = cross_val_score(pipeline, X_true, y_true, cv=LeaveOneOut(), scoring='r2')
        cv_r2 = cv_scores.mean()
        
        # è¿‡æ‹Ÿåˆç¨‹åº¦
        overfitting = train_r2 - cv_r2
        
        # ç»˜åˆ¶åŸå§‹æ•°æ®
        plt.scatter(X_true, y_true, alpha=0.7, s=50, color='black', label='åŸå§‹æ•°æ®')
        
        # ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿
        X_plot = np.linspace(0, 10, 100).reshape(-1, 1)
        X_plot_poly = poly.transform(X_plot)
        y_plot = model.predict(X_plot_poly)
        plt.plot(X_plot, y_plot, color=color, linewidth=2, label=f'{name}æ‹Ÿåˆ')
        
        # ç»˜åˆ¶çœŸå®å…³ç³»
        y_true_line = 2 * X_plot.flatten() + 3
        plt.plot(X_plot, y_true_line, '--', color='orange', alpha=0.8, label='çœŸå®å…³ç³»')
        
        plt.title(f'{name}\nè®­ç»ƒRÂ²={train_r2:.3f}, CV RÂ²={cv_r2:.3f}\nè¿‡æ‹Ÿåˆç¨‹åº¦={overfitting:.3f}')
        plt.xlabel('X')
        plt.ylabel('Y')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # åˆ¤æ–­è´¨é‡
        if overfitting > 0.3:
            quality = "è¿‡æ‹Ÿåˆä¸¥é‡"
            color_bg = 'red'
        elif cv_r2 > 0.3 and overfitting < 0.1:
            quality = "è‰¯å¥½"
            color_bg = 'green'
        else:
            quality = "ä¸€èˆ¬"
            color_bg = 'yellow'
        
        plt.text(0.02, 0.98, f'è´¨é‡: {quality}', transform=plt.gca().transAxes,
                bbox=dict(boxstyle='round', facecolor=color_bg, alpha=0.3),
                verticalalignment='top')
        
        print(f"\n{name}:")
        print(f"  è®­ç»ƒ RÂ²: {train_r2:.3f}")
        print(f"  äº¤å‰éªŒè¯ RÂ²: {cv_r2:.3f}")
        print(f"  è¿‡æ‹Ÿåˆç¨‹åº¦: {overfitting:.3f}")
        print(f"  è´¨é‡è¯„ä¼°: {quality}")
    
    plt.tight_layout()
    plt.savefig('/home/ubuntu/project/MSC/Msc_Project/overfitting_demonstration.png', 
                dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"\nğŸ“Š ç»“è®º:")
    print(f"1. é«˜æ¬¡å¤šé¡¹å¼åœ¨è®­ç»ƒæ•°æ®ä¸ŠRÂ²å¾ˆé«˜ï¼Œä½†åœ¨æ–°æ•°æ®ä¸Šè¡¨ç°å¾ˆå·®")
    print(f"2. è¿™å°±æ˜¯ä¸ºä»€ä¹ˆé«˜RÂ²å¯èƒ½è¡¨ç¤ºè¿‡æ‹Ÿåˆ")
    print(f"3. äº¤å‰éªŒè¯RÂ²æ›´èƒ½åæ˜ æ¨¡å‹çš„çœŸå®æ³›åŒ–èƒ½åŠ›")
    print(f"4. è¿‡æ‹Ÿåˆç¨‹åº¦ = è®­ç»ƒRÂ² - äº¤å‰éªŒè¯RÂ² > 0.3 æ—¶éœ€è¦è­¦æƒ•")

def explain_your_data_issue():
    """è§£é‡Šæ‚¨æ•°æ®ä¸­çš„è¿‡æ‹Ÿåˆé—®é¢˜"""
    
    print(f"\nğŸ¯ æ‚¨çš„æ•°æ®ä¸­çš„è¿‡æ‹Ÿåˆé—®é¢˜è§£é‡Š:")
    
    # æ¨¡æ‹Ÿæ‚¨çš„æ•°æ®æƒ…å†µ
    scenarios = [
        {
            'name': 'cs_density_std -> charging_time_mean',
            'train_r2': 0.4837,
            'cv_r2': 0.0000,
            'sample_size': 81
        },
        {
            'name': 'cluster_count -> charging_station_coverage',
            'train_r2': 0.5522,
            'cv_r2': 0.0000,
            'sample_size': 81
        }
    ]
    
    for scenario in scenarios:
        overfitting = scenario['train_r2'] - scenario['cv_r2']
        print(f"\næ¡ˆä¾‹: {scenario['name']}")
        print(f"  æ ·æœ¬é‡: {scenario['sample_size']}")
        print(f"  è®­ç»ƒ RÂ²: {scenario['train_r2']:.4f}  <- çœ‹èµ·æ¥å¾ˆå¥½ï¼")
        print(f"  äº¤å‰éªŒè¯ RÂ²: {scenario['cv_r2']:.4f}  <- å®é™…æ³›åŒ–èƒ½åŠ›")
        print(f"  è¿‡æ‹Ÿåˆç¨‹åº¦: {overfitting:.4f}  <- è¶…è¿‡0.3ï¼Œä¸¥é‡è¿‡æ‹Ÿåˆ")
        
        print(f"  ğŸ“ åˆ†æ:")
        print(f"     - æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Š'è¡¨ç°ä¼˜ç§€'({scenario['train_r2']:.1%})")
        print(f"     - ä½†å¯¹æ–°æ•°æ®çš„é¢„æµ‹èƒ½åŠ›ä¸º0")
        print(f"     - è¿™æ„å‘³ç€æ¨¡å‹å­¦åˆ°çš„æ˜¯å™ªå£°ï¼Œè€ŒéçœŸå®è§„å¾‹")
        print(f"     - åœ¨81ä¸ªæ ·æœ¬ä¸­ï¼Œè¿™ç§è¿‡æ‹Ÿåˆé£é™©å¾ˆé«˜")

if __name__ == '__main__':
    demonstrate_overfitting()
    explain_your_data_issue()
    print(f"\nğŸ’¡ è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ‚¨éœ€è¦æ’å€¼æ¥å¢åŠ æ ·æœ¬é‡çš„åŸå› ï¼")
    print(f"ğŸ“ˆ å›¾è¡¨ä¿å­˜ä¸º: overfitting_demonstration.png")
