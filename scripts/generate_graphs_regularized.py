#!/usr/bin/env python3
"""
ç”Ÿæˆå……ç”µæ¡©å¸ƒå±€ç‰¹å¾ä¸æ€§èƒ½æŒ‡æ ‡çš„æ•£ç‚¹å›¾åˆ†æ - é˜²è¿‡æ‹Ÿåˆç‰ˆæœ¬
é’ˆå¯¹å°æ ·æœ¬æ•°æ®é›†ä¼˜åŒ–ï¼Œå‡å°‘è¿‡æ‹Ÿåˆé£é™©
"""

import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from matplotlib.backends.backend_pdf import PdfPages
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import cross_val_score, LeaveOneOut
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

# è®¾ç½®matplotlibå‚æ•°
plt.rcParams['figure.dpi'] = 300
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['font.size'] = 12
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['axes.labelsize'] = 12
plt.rcParams['xtick.labelsize'] = 10
plt.rcParams['ytick.labelsize'] = 10
plt.rcParams['legend.fontsize'] = 10
plt.rcParams['figure.titlesize'] = 16

def fit_multiple_models_with_cv(x, y):
    """è®­ç»ƒå¤šä¸ªå›å½’æ¨¡å‹å¹¶ä½¿ç”¨äº¤å‰éªŒè¯é˜²æ­¢è¿‡æ‹Ÿåˆ"""
    try:
        # ç§»é™¤NaNå€¼
        mask = ~(np.isnan(x) | np.isnan(y))
        x_clean = x[mask]
        y_clean = y[mask]
        
        if len(x_clean) < 5:
            return None, None, 0.0, "insufficient_data", {}
        
        # é‡å¡‘æ•°æ®ä¸ºsklearnæ ¼å¼
        X = x_clean.reshape(-1, 1)
        
        # å®šä¹‰é’ˆå¯¹å°æ ·æœ¬ä¼˜åŒ–çš„æ¨¡å‹
        models = {
            'Linear': LinearRegression(),
            'Ridge': Ridge(alpha=1.0),  # æ·»åŠ æ­£åˆ™åŒ–
            'Lasso': Lasso(alpha=0.1),  # æ·»åŠ ç‰¹å¾é€‰æ‹©
            'Polynomial': Ridge(alpha=1.0),  # å¤šé¡¹å¼+æ­£åˆ™åŒ–
            'RandomForest_Small': RandomForestRegressor(
                n_estimators=10,  # å‡å°‘æ ‘çš„æ•°é‡
                max_depth=3,      # é™åˆ¶æ·±åº¦
                min_samples_split=5,  # å¢åŠ åˆ†è£‚è¦æ±‚
                random_state=42
            ),
            'GradientBoosting_Small': GradientBoostingRegressor(
                n_estimators=10,  # å¤§å¹…å‡å°‘æ ‘çš„æ•°é‡
                max_depth=2,      # é™åˆ¶æ·±åº¦
                learning_rate=0.3,  # å¢åŠ å­¦ä¹ ç‡è¡¥å¿æ ‘æ•°å‡å°‘
                min_samples_split=5,
                random_state=42
            ),
            'SVR_Simple': SVR(kernel='linear', C=1.0)  # ä½¿ç”¨çº¿æ€§æ ¸
        }
        
        model_results = {}
        best_model = None
        best_cv_score = -np.inf
        best_model_name = ""
        
        # ä½¿ç”¨ç•™ä¸€äº¤å‰éªŒè¯
        cv = LeaveOneOut()
        
        for name, model in models.items():
            try:
                if name == 'Polynomial':
                    # å¤šé¡¹å¼å›å½’
                    poly_features = PolynomialFeatures(degree=2)
                    X_poly = poly_features.fit_transform(X)
                    
                    # äº¤å‰éªŒè¯
                    cv_scores = cross_val_score(model, X_poly, y_clean, cv=cv, scoring='r2')
                    cv_r2 = cv_scores.mean()
                    
                    # è®­ç»ƒå®Œæ•´æ¨¡å‹ç”¨äºå¯è§†åŒ–
                    model.fit(X_poly, y_clean)
                    y_pred = model.predict(X_poly)
                    train_r2 = r2_score(y_clean, y_pred)
                    
                    # ç”Ÿæˆé¢„æµ‹æ›²çº¿
                    x_fit = np.linspace(x_clean.min(), x_clean.max(), 100).reshape(-1, 1)
                    X_fit_poly = poly_features.transform(x_fit)
                    y_fit = model.predict(X_fit_poly)
                else:
                    # å…¶ä»–æ¨¡å‹
                    # äº¤å‰éªŒè¯
                    cv_scores = cross_val_score(model, X, y_clean, cv=cv, scoring='r2')
                    cv_r2 = cv_scores.mean()
                    
                    # è®­ç»ƒå®Œæ•´æ¨¡å‹ç”¨äºå¯è§†åŒ–
                    model.fit(X, y_clean)
                    y_pred = model.predict(X)
                    train_r2 = r2_score(y_clean, y_pred)
                    
                    # ç”Ÿæˆé¢„æµ‹æ›²çº¿
                    x_fit = np.linspace(x_clean.min(), x_clean.max(), 100).reshape(-1, 1)
                    y_fit = model.predict(x_fit)
                
                # è®¡ç®—è¿‡æ‹Ÿåˆç¨‹åº¦
                overfitting = train_r2 - cv_r2
                
                model_results[name] = {
                    'train_r2': train_r2,
                    'cv_r2': cv_r2,
                    'overfitting': overfitting,
                    'x_fit': x_fit.flatten(),
                    'y_fit': y_fit,
                    'model': model
                }
                
                # é€‰æ‹©æœ€ä½³æ¨¡å‹ï¼šä¼˜å…ˆè€ƒè™‘äº¤å‰éªŒè¯åˆ†æ•°ï¼ŒåŒæ—¶æƒ©ç½šè¿‡æ‹Ÿåˆ
                score = cv_r2 - 0.5 * max(0, overfitting)  # æƒ©ç½šè¿‡æ‹Ÿåˆ
                
                if score > best_cv_score:
                    best_cv_score = score
                    best_model = name
                    best_model_name = name
                    
            except Exception as e:
                print(f"   âš ï¸ æ¨¡å‹ {name} è®­ç»ƒå¤±è´¥: {e}")
                continue
        
        if best_model is None:
            return None, None, 0.0, "no_valid_model", {}
        
        # è¿”å›æœ€ä½³æ¨¡å‹çš„ç»“æœï¼Œä½†ä½¿ç”¨äº¤å‰éªŒè¯RÂ²
        best_result = model_results[best_model]
        return (best_result['x_fit'], best_result['y_fit'], 
                best_result['cv_r2'], best_model_name, model_results)
        
    except Exception as e:
        print(f"âš ï¸ å¤šæ¨¡å‹æ‹Ÿåˆå¤±è´¥: {e}")
        return None, None, 0.0, "error", {}

def create_scatter_plot_with_validation(df, x_col, y_col, output_dir):
    """åˆ›å»ºå¸¦äº¤å‰éªŒè¯ä¿¡æ¯çš„æ•£ç‚¹å›¾"""
    try:
        # åˆ›å»ºå›¾å½¢
        fig, ax = plt.subplots(figsize=(12, 8))
        
        # è·å–æ•°æ®
        x = df[x_col].values
        y = df[y_col].values
        
        # åˆ›å»ºæ•£ç‚¹å›¾
        scatter = ax.scatter(x, y, alpha=0.7, s=80, color='steelblue', 
                           edgecolors='black', linewidth=0.5)
        
        # ä½¿ç”¨æ”¹è¿›çš„å¤šæ¨¡å‹æ‹Ÿåˆ
        x_fit, y_fit, cv_r2, best_model, model_results = fit_multiple_models_with_cv(x, y)
        
        # ç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿
        if x_fit is not None and y_fit is not None:
            # æ ¹æ®æ¨¡å‹ç±»å‹è®¾ç½®é¢œè‰²
            color_map = {
                'Linear': 'darkred',
                'Ridge': 'darkgreen',
                'Lasso': 'darkorange', 
                'Polynomial': 'red',
                'RandomForest_Small': 'green',
                'GradientBoosting_Small': 'blue',
                'SVR_Simple': 'purple'
            }
            color = color_map.get(best_model, 'darkred')
            ax.plot(x_fit, y_fit, color=color, linewidth=2.5,
                   label=f'{best_model} (CV RÂ² = {cv_r2:.3f})')
            
            # æ·»åŠ è¯¦ç»†çš„æ¨¡å‹æ¯”è¾ƒä¿¡æ¯
            if len(model_results) > 1:
                info_text = f"æœ€ä½³æ¨¡å‹: {best_model}\\n"
                info_text += f"äº¤å‰éªŒè¯ RÂ²: {cv_r2:.3f}\\n"
                
                best_result = model_results[best_model]
                info_text += f"è®­ç»ƒ RÂ²: {best_result['train_r2']:.3f}\\n"
                info_text += f"è¿‡æ‹Ÿåˆç¨‹åº¦: {best_result['overfitting']:.3f}\\n"
                
                # æ˜¾ç¤ºå‰3ä¸ªæ¨¡å‹çš„äº¤å‰éªŒè¯ç»“æœ
                sorted_models = sorted(model_results.items(), 
                                     key=lambda x: x[1]['cv_r2'], reverse=True)
                info_text += "\\nTop 3 (CV RÂ²):\\n"
                for i, (name, result) in enumerate(sorted_models[:3]):
                    info_text += f"{i+1}. {name}: {result['cv_r2']:.3f}\\n"
                
                # åˆ›å»ºæ–‡æœ¬æ¡†
                ax.text(0.02, 0.98, info_text.strip(), transform=ax.transAxes, 
                       fontsize=9, verticalalignment='top', 
                       bbox=dict(boxstyle='round,pad=0.5', facecolor='lightblue', alpha=0.8))
        
        # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
        ax.set_xlabel(x_col, fontsize=12, fontweight='bold')
        ax.set_ylabel(y_col, fontsize=12, fontweight='bold')
        ax.set_title(f'{x_col} vs {y_col}\\n(é˜²è¿‡æ‹Ÿåˆç‰ˆæœ¬)', fontsize=14, fontweight='bold', pad=20)
        
        # æ·»åŠ ç½‘æ ¼
        ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)
        
        # æ·»åŠ å›¾ä¾‹
        if x_fit is not None:
            ax.legend(loc='upper right', framealpha=0.8)
        
        # è®¾ç½®æ ·å¼
        ax.spines['top'].set_visible(False)
        ax.spines['right'].set_visible(False)
        ax.spines['left'].set_linewidth(1)
        ax.spines['bottom'].set_linewidth(1)
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout()
        
        # ä¿å­˜å›¾ç‰‡
        filename = f"{x_col}_{y_col}_regularized.png"
        filepath = os.path.join(output_dir, filename)
        plt.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white')
        plt.close()
        
        return filepath, cv_r2, best_model
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºå›¾è¡¨å¤±è´¥ {x_col} vs {y_col}: {e}")
        plt.close()
        return None, 0.0, "error"

def generate_regularized_plots(df, feature_cols, performance_cols, output_dir):
    """ç”Ÿæˆé˜²è¿‡æ‹Ÿåˆçš„æ•£ç‚¹å›¾"""
    print(f"\\nğŸ¨ å¼€å§‹ç”Ÿæˆé˜²è¿‡æ‹Ÿåˆå›¾è¡¨...")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    # å­˜å‚¨ç»“æœç»Ÿè®¡
    results = []
    success_count = 0
    total_count = len(feature_cols) * len(performance_cols)
    
    # åˆ›å»ºPDFåˆé›†
    pdf_path = os.path.join(output_dir, "regularized_scatter_plots.pdf")
    
    with PdfPages(pdf_path) as pdf:
        for i, x_col in enumerate(feature_cols, 1):
            print(f"\\nğŸ“Š å¤„ç†ç‰¹å¾å˜é‡ [{i}/{len(feature_cols)}]: {x_col}")
            
            for j, y_col in enumerate(performance_cols[:5]):  # å…ˆå¤„ç†å‰5ä¸ªæ€§èƒ½æŒ‡æ ‡ä½œä¸ºæµ‹è¯•
                print(f"   ğŸ“ˆ [{j+1}/5] {y_col}...", end="")
                
                try:
                    # åˆ›å»ºå›¾å½¢ç”¨äºPDF
                    fig, ax = plt.subplots(figsize=(12, 8))
                    
                    # è·å–æ•°æ®
                    x = df[x_col].values
                    y = df[y_col].values
                    
                    # åˆ›å»ºæ•£ç‚¹å›¾
                    ax.scatter(x, y, alpha=0.7, s=80, color='steelblue', 
                             edgecolors='black', linewidth=0.5)
                    
                    # ä½¿ç”¨æ”¹è¿›çš„å¤šæ¨¡å‹æ‹Ÿåˆ
                    x_fit, y_fit, cv_r2, best_model, model_results = fit_multiple_models_with_cv(x, y)
                    
                    # ç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿
                    if x_fit is not None and y_fit is not None:
                        color_map = {
                            'Linear': 'darkred',
                            'Ridge': 'darkgreen',
                            'Lasso': 'darkorange', 
                            'Polynomial': 'red',
                            'RandomForest_Small': 'green',
                            'GradientBoosting_Small': 'blue',
                            'SVR_Simple': 'purple'
                        }
                        color = color_map.get(best_model, 'darkred')
                        ax.plot(x_fit, y_fit, color=color, linewidth=2.5,
                               label=f'{best_model} (CV RÂ² = {cv_r2:.3f})')
                        
                        # æ·»åŠ è¯¦ç»†ä¿¡æ¯
                        if len(model_results) > 1:
                            best_result = model_results[best_model]
                            info_text = f"Best: {best_model}\\n"
                            info_text += f"CV RÂ²: {cv_r2:.3f}\\n"
                            info_text += f"Train RÂ²: {best_result['train_r2']:.3f}\\n"
                            info_text += f"Overfitting: {best_result['overfitting']:.3f}"
                            
                            ax.text(0.02, 0.98, info_text, transform=ax.transAxes, 
                                   fontsize=9, verticalalignment='top', 
                                   bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))
                    
                    # è®¾ç½®æ ‡ç­¾å’Œæ ‡é¢˜
                    ax.set_xlabel(x_col, fontsize=12, fontweight='bold')
                    ax.set_ylabel(y_col, fontsize=12, fontweight='bold')
                    ax.set_title(f'{x_col} vs {y_col} (Regularized)', fontsize=14, fontweight='bold', pad=20)
                    
                    # æ·»åŠ ç½‘æ ¼å’Œå›¾ä¾‹
                    ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5)
                    if x_fit is not None:
                        ax.legend(loc='upper right', framealpha=0.8)
                    
                    # è®¾ç½®æ ·å¼
                    ax.spines['top'].set_visible(False)
                    ax.spines['right'].set_visible(False)
                    
                    # è°ƒæ•´å¸ƒå±€
                    plt.tight_layout()
                    
                    # ä¿å­˜åˆ°PDF
                    pdf.savefig(fig, dpi=300, bbox_inches='tight')
                    
                    # ä¿å­˜å•ç‹¬çš„PNGæ–‡ä»¶
                    filename = f"{x_col}_{y_col}_regularized.png"
                    filepath = os.path.join(output_dir, filename)
                    plt.savefig(filepath, dpi=300, bbox_inches='tight', facecolor='white')
                    plt.close()
                    
                    # è®°å½•ç»“æœ
                    if len(model_results) > 0 and best_model in model_results:
                        best_result = model_results[best_model]
                        results.append({
                            'feature': x_col,
                            'performance': y_col,
                            'cv_r2': cv_r2,
                            'train_r2': best_result.get('train_r2', 0),
                            'overfitting': best_result.get('overfitting', 0),
                            'best_model': best_model,
                            'filename': filename
                        })
                    
                    success_count += 1
                    print(f" âœ… (CV RÂ²={cv_r2:.3f})")
                    
                except Exception as e:
                    print(f" âŒ å¤±è´¥: {e}")
                    plt.close()
                    continue
    
    # ä¿å­˜ç»“æœç»Ÿè®¡
    if results:
        results_df = pd.DataFrame(results)
        results_csv = os.path.join(output_dir, "regularized_results_summary.csv")
        results_df.to_csv(results_csv, index=False)
        
        print(f"\\nğŸ‰ é˜²è¿‡æ‹Ÿåˆå›¾è¡¨ç”Ÿæˆå®Œæˆï¼")
        print(f"âœ… æˆåŠŸç”Ÿæˆ: {success_count} å¼ å›¾è¡¨")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ“„ PDFåˆé›†: {pdf_path}")
        print(f"ğŸ“Š ç»“æœç»Ÿè®¡: {results_csv}")
        
        # æ˜¾ç¤ºæ”¹è¿›çš„ç»Ÿè®¡ä¿¡æ¯
        if len(results_df) > 0:
            print(f"\\nğŸ“ˆ äº¤å‰éªŒè¯è´¨é‡ç»Ÿè®¡:")
            print(f"   - å¹³å‡ CV RÂ²: {results_df['cv_r2'].mean():.3f}")
            print(f"   - æœ€é«˜ CV RÂ²: {results_df['cv_r2'].max():.3f}")
            print(f"   - CV RÂ² > 0.3: {len(results_df[results_df['cv_r2'] > 0.3])} å¼ ")
            print(f"   - å¹³å‡è¿‡æ‹Ÿåˆç¨‹åº¦: {results_df['overfitting'].mean():.3f}")
            
            print(f"\\nğŸ¯ æœ€ä½³æ¨¡å‹åˆ†å¸ƒ:")
            model_counts = results_df['best_model'].value_counts()
            for model, count in model_counts.items():
                avg_cv_r2 = results_df[results_df['best_model'] == model]['cv_r2'].mean()
                avg_overfitting = results_df[results_df['best_model'] == model]['overfitting'].mean()
                print(f"   - {model}: {count} å¼  (CV RÂ²={avg_cv_r2:.3f}, è¿‡æ‹Ÿåˆ={avg_overfitting:.3f})")
    
    return results_df if results else pd.DataFrame()

def main():
    print("ğŸš€ å¼€å§‹ç”Ÿæˆé˜²è¿‡æ‹Ÿåˆçš„å……ç”µæ¡©å¸ƒå±€ç‰¹å¾ä¸æ€§èƒ½æŒ‡æ ‡æ•£ç‚¹å›¾")
    
    # è®¾ç½®è·¯å¾„
    data_file = "/home/ubuntu/project/MSC/Msc_Project/models/input/merged_dataset.csv"
    output_dir = "/home/ubuntu/project/MSC/Msc_Project/models/plots_regularized"
    
    print(f"ğŸ“Š æ•°æ®æ–‡ä»¶: {data_file}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not os.path.exists(data_file):
        print(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_file}")
        return 1
    
    # åŠ è½½æ•°æ®
    try:
        df = pd.read_csv(data_file)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return 1
    
    # å®šä¹‰ç‰¹å¾å’Œæ€§èƒ½æŒ‡æ ‡
    layout_features = [col for col in df.columns 
                      if col not in ['layout_id'] and 
                      not col.startswith(('duration_', 'charging_', 'waiting_', 'energy_', 'vehicle_', 'reroute_', 'ev_'))]
    
    performance_metrics = [col for col in df.columns 
                          if col.startswith(('duration_', 'charging_', 'waiting_', 'energy_', 'vehicle_', 'reroute_', 'ev_'))]
    
    if not layout_features or not performance_metrics:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„ç‰¹å¾æˆ–æ€§èƒ½æŒ‡æ ‡åˆ—")
        return 1
    
    print(f"ğŸ“Š æ‰¾åˆ° {len(layout_features)} ä¸ªå¸ƒå±€ç‰¹å¾")
    print(f"ğŸ“ˆ æ‰¾åˆ° {len(performance_metrics)} ä¸ªæ€§èƒ½æŒ‡æ ‡")
    
    # ç”Ÿæˆé˜²è¿‡æ‹Ÿåˆå›¾è¡¨
    results_df = generate_regularized_plots(df, layout_features, performance_metrics, output_dir)
    
    if len(results_df) > 0:
        print(f"\\nğŸ“ é˜²è¿‡æ‹Ÿåˆå›¾è¡¨å·²ç”Ÿæˆå®Œæ¯•ï¼")
        print(f"ğŸ“ æ‰€æœ‰å›¾è¡¨ä¿å­˜åœ¨: {output_dir}")
        print(f"ğŸ“ å›¾è¡¨å‘½åè§„åˆ™: ç‰¹å¾å˜é‡_æ€§èƒ½æŒ‡æ ‡_regularized.png")
        print(f"ğŸ“‘ PDFåˆé›†å’Œç»“æœç»Ÿè®¡å¯ç›´æ¥ç”¨äºè®ºæ–‡")
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•å›¾è¡¨")
        return 1
    
    return 0

if __name__ == '__main__':
    exit(main())
