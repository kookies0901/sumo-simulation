import os
import sys
import csv
import json
import argparse
import subprocess
import xml.etree.ElementTree as ET
import pandas as pd
import logging
import gzip
from datetime import datetime
from vehicle_config import load_vehicle_config

def load_scenario_matrix(matrix_file):
    """åŠ è½½åœºæ™¯çŸ©é˜µ"""
    scenarios = []
    with open(matrix_file, 'r') as f:
        reader = csv.DictReader(f)
        for row in reader:
            scenarios.append(row)
    return scenarios

def create_sumo_config(scenario_id, rou_file, cs_file, net_file, output_dir):
    """åˆ›å»ºSUMOé…ç½®æ–‡ä»¶"""
    # é…ç½®æ–‡ä»¶åº”è¯¥æ”¾åœ¨åœºæ™¯æ ¹ç›®å½•ï¼Œä¸æ˜¯outputç›®å½•
    scenario_dir = os.path.dirname(output_dir)
    config_file = os.path.join(scenario_dir, f"{scenario_id}.sumocfg")
    
    # åˆ›å»ºåœºæ™¯ç›®å½•
    os.makedirs(scenario_dir, exist_ok=True)
    
    # é…ç½®æ–‡ä»¶å†…å®¹
    config_content = f"""<?xml version="1.0" encoding="UTF-8"?>
<configuration>
    <input>
        <net-file value="{os.path.relpath(net_file, scenario_dir)}"/>
        <route-files value="{os.path.relpath(rou_file, scenario_dir)}"/>
        <additional-files value="{os.path.relpath(cs_file, scenario_dir)},{os.path.relpath('data/vehicles.add.xml', scenario_dir)}"/>
    </input>
    <time>
        <begin value="0"/>
        <end value="20000"/>
    </time>
    <report>
        <verbose value="true"/>
        <no-step-log value="true"/>
    </report>
    <output>
        <tripinfo-output value="output/tripinfo_output.xml.gz"/>
        <chargingstations-output value="output/chargingevents.xml.gz"/>
        <battery-output value="output/battery_output.xml.gz"/>
        <tripinfo-output.write-unfinished value="true"/>
        <summary-output value="output/summary_output.xml.gz"/>
    </output>
</configuration>"""
    
    with open(config_file, 'w') as f:
        f.write(config_content)
    
    return config_file

def run_simulation(config_file, output_dir):
    """è¿è¡ŒSUMOä»¿çœŸ"""
    try:
        # ä½¿ç”¨åœºæ™¯ç›®å½•ä½œä¸ºå·¥ä½œç›®å½•
        scenario_dir = os.path.dirname(output_dir)
        config_filename = os.path.basename(config_file)
        
        logging.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯:")
        logging.info(f"   - é…ç½®æ–‡ä»¶: {config_file}")
        logging.info(f"   - åœºæ™¯ç›®å½•: {scenario_dir}")
        logging.info(f"   - è¾“å‡ºç›®å½•: {output_dir}")
        logging.info(f"   - å·¥ä½œç›®å½•: {scenario_dir}")
        logging.info(f"   - æ‰§è¡Œå‘½ä»¤: /usr/bin/time -v sumo -c {config_filename}")
        
        # æ£€æŸ¥é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(config_file):
            logging.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
            return False
            
        # æ£€æŸ¥å·¥ä½œç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(scenario_dir):
            logging.error(f"âŒ åœºæ™¯ç›®å½•ä¸å­˜åœ¨: {scenario_dir}")
            return False
        
        # åˆ›å»ºæ—¶é—´æ—¥å¿—æ–‡ä»¶
        time_log_file = os.path.join(output_dir, "sumo.time.log")
        
        # ä½¿ç”¨ /usr/bin/time -v è¿è¡Œä»¿çœŸå¹¶è®°å½•è¯¦ç»†èµ„æºä½¿ç”¨æƒ…å†µ
        result = subprocess.run(
            ["/usr/bin/time", "-v", "sumo", "-c", config_filename],
            cwd=scenario_dir,
            capture_output=True,
            text=True,
            check=True
        )
        
        # è§£ææ—¶é—´è¾“å‡ºä¸­çš„èµ„æºä½¿ç”¨ä¿¡æ¯
        time_output = result.stderr  # time å‘½ä»¤çš„è¾“å‡ºåœ¨ stderr
        resource_info = {}
        
        for line in time_output.split('\n'):
            line = line.strip()
            if ':' in line:
                key, value = line.split(':', 1)
                key = key.strip()
                value = value.strip()
                resource_info[key] = value
        
        # è®°å½•èµ„æºä½¿ç”¨æƒ…å†µ
        logging.info(f"âœ… ä»¿çœŸå®Œæˆ")
        logging.info(f"ğŸ“Š èµ„æºä½¿ç”¨æƒ…å†µ:")
        if 'Maximum resident set size (kbytes)' in resource_info:
            max_memory_kb = resource_info['Maximum resident set size (kbytes)']
            max_memory_mb = float(max_memory_kb) / 1024
            logging.info(f"   - æœ€å¤§å†…å­˜ä½¿ç”¨: {max_memory_mb:.2f} MB ({max_memory_kb} KB)")
        
        if 'User time (seconds)' in resource_info:
            user_time = resource_info['User time (seconds)']
            logging.info(f"   - ç”¨æˆ·æ—¶é—´: {user_time} ç§’")
        
        if 'System time (seconds)' in resource_info:
            system_time = resource_info['System time (seconds)']
            logging.info(f"   - ç³»ç»Ÿæ—¶é—´: {system_time} ç§’")
        
        if 'Elapsed (wall clock) time (h:mm:ss or m:ss)' in resource_info:
            elapsed_time = resource_info['Elapsed (wall clock) time (h:mm:ss or m:ss)']
            logging.info(f"   - æ€»è¿è¡Œæ—¶é—´: {elapsed_time}")
        
        # ä¿å­˜è¯¦ç»†çš„æ—¶é—´æ—¥å¿—
        with open(time_log_file, 'w', encoding='utf-8') as f:
            f.write("=== SUMO ä»¿çœŸèµ„æºä½¿ç”¨è¯¦æƒ… ===\n")
            f.write(f"é…ç½®æ–‡ä»¶: {config_file}\n")
            f.write(f"è¿è¡Œæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write("=== æ ‡å‡†è¾“å‡º ===\n")
            f.write(result.stdout)
            f.write("\n\n=== èµ„æºä½¿ç”¨è¯¦æƒ… ===\n")
            f.write(time_output)
        
        logging.info(f"ğŸ“„ è¯¦ç»†æ—¥å¿—ä¿å­˜åˆ°: {time_log_file}")
        logging.info(f"ğŸ“„ æ ‡å‡†è¾“å‡º: {result.stdout[:500]}...")  # åªæ˜¾ç¤ºå‰500å­—ç¬¦
        
        return True
    except subprocess.CalledProcessError as e:
        logging.error(f"âŒ ä»¿çœŸå¤±è´¥:")
        logging.error(f"   è¿”å›ç : {e.returncode}")
        logging.error(f"   æ ‡å‡†è¾“å‡º: {e.stdout}")
        logging.error(f"   é”™è¯¯è¾“å‡º: {e.stderr}")
        
        # å³ä½¿å¤±è´¥ä¹Ÿå°è¯•è§£æèµ„æºä½¿ç”¨ä¿¡æ¯
        if e.stderr:
            time_output = e.stderr
            resource_info = {}
            for line in time_output.split('\n'):
                line = line.strip()
                if ':' in line:
                    key, value = line.split(':', 1)
                    key = key.strip()
                    value = value.strip()
                    resource_info[key] = value
            
            if 'Maximum resident set size (kbytes)' in resource_info:
                max_memory_kb = resource_info['Maximum resident set size (kbytes)']
                max_memory_mb = float(max_memory_kb) / 1024
                logging.error(f"   æœ€å¤§å†…å­˜ä½¿ç”¨: {max_memory_mb:.2f} MB ({max_memory_kb} KB)")
        
        return False
    except Exception as e:
        logging.error(f"âŒ å…¶ä»–é”™è¯¯: {e}")
        return False

def parse_charging_data(output_dir, vehicle_config):
    """è§£æå……ç”µæ•°æ®"""
    battery_file = os.path.join(output_dir, "battery_output.xml.gz")
    charging_events_file = os.path.join(output_dir, "chargingevents.xml.gz")
    summary_file = os.path.join(output_dir, "summary_output.xml.gz")
    
    data = {
        'avg_waiting_time': 0.0,
        'avg_charging_time': 0.0,
        'ev_count': 0,
        'avg_initial_soc': 0.0,
        'avg_final_soc': 0.0,
        'simulation_duration': 0.0
    }
    
    # è§£æç”µæ± æ•°æ®
    if os.path.exists(battery_file):
        try:
            # å¤„ç†å‹ç¼©çš„XMLæ–‡ä»¶
            with gzip.open(battery_file, 'rt', encoding='utf-8') as f:
                tree = ET.parse(f)
                root = tree.getroot()
            
            ev_vehicles = set()
            initial_capacities = {}
            final_capacities = {}
            max_battery_capacity = vehicle_config["capacity"]
            
            for timestep in root.findall("timestep"):
                for vehicle in timestep.findall("vehicle"):
                    veh_id = vehicle.get("id")
                    if veh_id.startswith("EV_"):
                        ev_vehicles.add(veh_id)
                        actual_capacity = float(vehicle.get("chargeLevel", 0))
                        
                        if veh_id not in initial_capacities:
                            initial_capacities[veh_id] = actual_capacity
                        final_capacities[veh_id] = actual_capacity
            
            if initial_capacities and final_capacities:
                initial_socs = [cap / max_battery_capacity for cap in initial_capacities.values()]
                final_socs = [cap / max_battery_capacity for cap in final_capacities.values()]
                
                data['ev_count'] = len(ev_vehicles)
                data['avg_initial_soc'] = sum(initial_socs) / len(initial_socs) if initial_socs else 0.0
                data['avg_final_soc'] = sum(final_socs) / len(final_socs) if final_socs else 0.0
                
        except Exception as e:
            print(f"âš ï¸ è§£æç”µæ± æ•°æ®å¤±è´¥: {e}")
    
    # è§£æå……ç”µäº‹ä»¶æ•°æ®
    if os.path.exists(charging_events_file):
        try:
            # å¤„ç†å‹ç¼©çš„XMLæ–‡ä»¶
            with gzip.open(charging_events_file, 'rt', encoding='utf-8') as f:
                tree = ET.parse(f)
                root = tree.getroot()
            
            waiting_times = []
            charging_times = []
            
            for event in root.findall("chargingEvent"):
                waiting_time = float(event.get("waitingTime", 0))
                charging_time = float(event.get("chargingTime", 0))
                
                if waiting_time > 0:
                    waiting_times.append(waiting_time)
                if charging_time > 0:
                    charging_times.append(charging_time)
            
            if waiting_times:
                data['avg_waiting_time'] = sum(waiting_times) / len(waiting_times)
            if charging_times:
                data['avg_charging_time'] = sum(charging_times) / len(charging_times)
                
        except Exception as e:
            print(f"âš ï¸ è§£æå……ç”µäº‹ä»¶æ•°æ®å¤±è´¥: {e}")
    
    # è§£ææ‘˜è¦æ•°æ®
    if os.path.exists(summary_file):
        try:
            # å¤„ç†å‹ç¼©çš„XMLæ–‡ä»¶
            with gzip.open(summary_file, 'rt', encoding='utf-8') as f:
                tree = ET.parse(f)
                root = tree.getroot()
            
            for step in root.findall("step"):
                data['simulation_duration'] = float(step.get("time", 0))
                break
                
        except Exception as e:
            print(f"âš ï¸ è§£ææ‘˜è¦æ•°æ®å¤±è´¥: {e}")
    
    return data

def save_results(results, output_file):
    """ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶"""
    df = pd.DataFrame(results)
    df.to_csv(output_file, index=False)
    print(f"âœ… ç»“æœä¿å­˜åˆ°: {output_file}")

def run_single_scenario(scenario_id, cs_layout_id, rou_type, data_dir, output_dir):
    """è¿è¡Œå•ä¸ªåœºæ™¯"""
    logging.info(f"ğŸ¯ è¿è¡Œåœºæ™¯: {scenario_id} ({cs_layout_id} + {rou_type})")
    
    # æ–‡ä»¶è·¯å¾„
    rou_file = os.path.join(data_dir, "routes", f"{rou_type}.rou.xml")
    cs_file = os.path.join(data_dir, "cs", f"{cs_layout_id}.xml")
    net_file = os.path.join(data_dir, "map", "glasgow_clean.net.xml")
    
    logging.info(f"ğŸ“ æ–‡ä»¶è·¯å¾„:")
    logging.info(f"   - è·¯ç”±æ–‡ä»¶: {rou_file}")
    logging.info(f"   - å……ç”µç«™æ–‡ä»¶: {cs_file}")
    logging.info(f"   - ç½‘ç»œæ–‡ä»¶: {net_file}")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(rou_file):
        logging.error(f"âŒ è·¯ç”±æ–‡ä»¶ä¸å­˜åœ¨: {rou_file}")
        return None
    if not os.path.exists(cs_file):
        logging.error(f"âŒ å……ç”µç«™æ–‡ä»¶ä¸å­˜åœ¨: {cs_file}")
        return None
    if not os.path.exists(net_file):
        logging.error(f"âŒ ç½‘ç»œæ–‡ä»¶ä¸å­˜åœ¨: {net_file}")
        return None
    
    # åˆ›å»ºåœºæ™¯è¾“å‡ºç›®å½•
    scenario_output_dir = os.path.join(output_dir, scenario_id, "output")
    os.makedirs(scenario_output_dir, exist_ok=True)
    logging.info(f"   - è¾“å‡ºç›®å½•: {scenario_output_dir}")
    
    # åˆ›å»ºSUMOé…ç½®
    config_file = create_sumo_config(scenario_id, rou_file, cs_file, net_file, scenario_output_dir)
    
    # è¿è¡Œä»¿çœŸ
    success = run_simulation(config_file, scenario_output_dir)
    
    if success:
        # è§£ææ•°æ®
        vehicle_config = load_vehicle_config()
        data = parse_charging_data(scenario_output_dir, vehicle_config)
        
        # æ·»åŠ åœºæ™¯ä¿¡æ¯
        data['scenario_id'] = scenario_id
        data['cs_layout_id'] = cs_layout_id
        data['rou_type'] = rou_type
        
        return data
    else:
        return None

def run_all_scenarios(matrix_file, data_dir, output_dir):
    """è¿è¡Œæ‰€æœ‰åœºæ™¯"""
    print(f"ğŸš€ å¼€å§‹è¿è¡Œæ‰€æœ‰åœºæ™¯")
    
    # åŠ è½½åœºæ™¯çŸ©é˜µ
    scenarios = load_scenario_matrix(matrix_file)
    print(f"ğŸ“Š åŠ è½½äº† {len(scenarios)} ä¸ªåœºæ™¯")
    
    # è¿è¡Œæ‰€æœ‰åœºæ™¯
    results = []
    for i, scenario in enumerate(scenarios, 1):
        print(f"\n[{i}/{len(scenarios)}] å¤„ç†åœºæ™¯: {scenario['scenario_id']}")
        
        data = run_single_scenario(
            scenario['scenario_id'],
            scenario['cs_layout_id'],
            scenario['rou_type'],
            data_dir,
            output_dir
        )
        
        if data:
            results.append(data)
            print(f"âœ… åœºæ™¯ {scenario['scenario_id']} å®Œæˆ")
        else:
            print(f"âŒ åœºæ™¯ {scenario['scenario_id']} å¤±è´¥")
    
    # ä¿å­˜ç»“æœ
    if results:
        result_file = os.path.join(output_dir, "charging_analysis.csv")
        save_results(results, result_file)
        print(f"\nğŸ‰ æ‰€æœ‰åœºæ™¯è¿è¡Œå®Œæˆï¼å…±æˆåŠŸè¿è¡Œ {len(results)} ä¸ªåœºæ™¯")
    else:
        print(f"\nâŒ æ²¡æœ‰æˆåŠŸè¿è¡Œçš„åœºæ™¯")

def main():
    # è®¾ç½®æ—¥å¿—
    log_dir = "logs"
    os.makedirs(log_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(log_dir, f"simulation_{timestamp}.log")
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler(sys.stdout)
        ]
    )
    
    logging.info(f"ğŸš€ å¼€å§‹è¿è¡Œä»¿çœŸï¼Œæ—¥å¿—æ–‡ä»¶: {log_file}")
    
    parser = argparse.ArgumentParser(description='è¿è¡Œå…¨å±€ä»¿çœŸ')
    parser.add_argument('--matrix', type=str, 
                       default='data/scenario_matrix.csv',
                       help='åœºæ™¯çŸ©é˜µæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--data_dir', type=str, 
                       default='data',
                       help='æ•°æ®ç›®å½•è·¯å¾„')
    parser.add_argument('--output_dir', type=str, 
                       default='sumo',
                       help='è¾“å‡ºç›®å½•è·¯å¾„')
    parser.add_argument('-s', '--scenario', type=str,
                       help='è¿è¡Œå•ä¸ªåœºæ™¯ (æ ¼å¼: S001)')
    
    args = parser.parse_args()
    
    if args.scenario:
        # è¿è¡Œå•ä¸ªåœºæ™¯
        scenarios = load_scenario_matrix(args.matrix)
        target_scenario = None
        
        for scenario in scenarios:
            if scenario['scenario_id'] == args.scenario:
                target_scenario = scenario
                break
        
        if target_scenario:
            data = run_single_scenario(
                target_scenario['scenario_id'],
                target_scenario['cs_layout_id'],
                target_scenario['rou_type'],
                args.data_dir,
                args.output_dir
            )
            
            if data:
                # ä¿å­˜å•ä¸ªåœºæ™¯ç»“æœ
                result_file = os.path.join(args.output_dir, target_scenario['scenario_id'], "result", "charging_analysis.csv")
                os.makedirs(os.path.dirname(result_file), exist_ok=True)
                save_results([data], result_file)
                print(f"âœ… å•ä¸ªåœºæ™¯è¿è¡Œå®Œæˆ: {args.scenario}")
            else:
                print(f"âŒ å•ä¸ªåœºæ™¯è¿è¡Œå¤±è´¥: {args.scenario}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°åœºæ™¯: {args.scenario}")
    else:
        # è¿è¡Œæ‰€æœ‰åœºæ™¯
        run_all_scenarios(args.matrix, args.data_dir, args.output_dir)

if __name__ == '__main__':
    main() 