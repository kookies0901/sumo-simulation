#!/usr/bin/env python3
"""
è¯¦ç»†çš„æ¨¡å‹æ¯”è¾ƒåˆ†æ - è§£é‡Šä¸ºä»€ä¹ˆé€‰æ‹©Linearå’ŒPolynomialè€Œä¸æ˜¯å¤æ‚æ¨¡å‹
å…³é”®é—®é¢˜ï¼šå³ä½¿Linear/Polynomialä¹Ÿæœ‰é«˜RÂ²ï¼Œä¸ºä»€ä¹ˆå®ƒä»¬æ›´å¥½ï¼Ÿ
"""

import os
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.svm import SVR
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import cross_val_score, LeaveOneOut
from sklearn.pipeline import Pipeline
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

def comprehensive_model_comparison(x, y, feature_name, target_name):
    """å…¨é¢æ¯”è¾ƒæ‰€æœ‰æ¨¡å‹çš„è¡¨ç°ï¼Œé‡ç‚¹åˆ†ææ³›åŒ–èƒ½åŠ›å·®å¼‚"""
    
    # ç§»é™¤NaNå€¼
    mask = ~(np.isnan(x) | np.isnan(y))
    x_clean = x[mask]
    y_clean = y[mask]
    
    if len(x_clean) < 10:
        return None
    
    X = x_clean.reshape(-1, 1)
    
    print(f"\nğŸ” è¯¦ç»†åˆ†æ: {feature_name} vs {target_name}")
    print(f"ğŸ“Š æ ·æœ¬æ•°é‡: {len(x_clean)}")
    
    # å®šä¹‰æ‰€æœ‰æ¨¡å‹
    models = {
        'Linear': {
            'model': LinearRegression(),
            'is_complex': False,
            'params': 'N/A'
        },
        'Polynomial': {
            'model': Pipeline([
                ('poly', PolynomialFeatures(degree=2)),
                ('linear', LinearRegression())
            ]),
            'is_complex': False,
            'params': 'degree=2'
        },
        'RandomForest': {
            'model': RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42),
            'is_complex': True,
            'params': 'n_estimators=50, max_depth=5'
        },
        'GradientBoosting': {
            'model': GradientBoostingRegressor(n_estimators=50, max_depth=3, random_state=42),
            'is_complex': True,
            'params': 'n_estimators=50, max_depth=3'
        },
        'SVR': {
            'model': SVR(kernel='rbf', C=1.0, gamma='scale'),
            'is_complex': True,
            'params': 'kernel=rbf, C=1.0'
        }
    }
    
    results = []
    
    # çš®å°”é€Šç›¸å…³ç³»æ•°
    pearson_r, pearson_p = stats.pearsonr(x_clean, y_clean)
    print(f"ğŸ“ˆ çš®å°”é€Šç›¸å…³ç³»æ•°: r = {pearson_r:.4f}, p = {pearson_p:.4f}")
    
    for name, model_info in models.items():
        try:
            model = model_info['model']
            
            # è®­ç»ƒæ¨¡å‹
            model.fit(X, y_clean)
            y_pred_train = model.predict(X)
            train_r2 = r2_score(y_clean, y_pred_train)
            train_mse = mean_squared_error(y_clean, y_pred_train)
            
            # äº¤å‰éªŒè¯ (å…³é”®æŒ‡æ ‡!)
            cv_scores = cross_val_score(model, X, y_clean, cv=LeaveOneOut(), scoring='r2')
            cv_scores_clean = cv_scores[~np.isnan(cv_scores) & ~np.isinf(cv_scores)]
            cv_r2 = cv_scores_clean.mean() if len(cv_scores_clean) > 0 else 0.0
            cv_std = cv_scores_clean.std() if len(cv_scores_clean) > 0 else 0.0
            
            # è®¡ç®—å…³é”®æŒ‡æ ‡
            overfitting = train_r2 - cv_r2
            generalization_ratio = cv_r2 / train_r2 if train_r2 > 0 else 0
            
            # ç¨³å®šæ€§åˆ†æï¼šäº¤å‰éªŒè¯åˆ†æ•°çš„å˜å¼‚ç³»æ•°
            cv_stability = cv_std / abs(cv_r2) if cv_r2 != 0 else float('inf')
            
            # æ¨¡å‹å¤æ‚åº¦è¯„ä¼°
            if name == 'Linear':
                complexity_score = 1  # æœ€ç®€å•
            elif name == 'Polynomial':
                complexity_score = 2  # ä¸­ç­‰
            else:
                complexity_score = 3  # å¤æ‚
            
            # è®¡ç®—ç»¼åˆè¯„åˆ† (é‡ç‚¹ï¼šå¹³è¡¡æ‹Ÿåˆèƒ½åŠ›ä¸æ³›åŒ–èƒ½åŠ›)
            if cv_r2 > 0:
                # ç»¼åˆè¯„åˆ†ï¼šäº¤å‰éªŒè¯RÂ² - è¿‡æ‹Ÿåˆæƒ©ç½š - å¤æ‚åº¦æƒ©ç½š
                composite_score = cv_r2 - 0.5 * max(0, overfitting) - 0.1 * (complexity_score - 1)
            else:
                composite_score = -1
            
            results.append({
                'model': name,
                'is_complex': model_info['is_complex'],
                'params': model_info['params'],
                'train_r2': train_r2,
                'cv_r2': cv_r2,
                'cv_std': cv_std,
                'overfitting': overfitting,
                'generalization_ratio': generalization_ratio,
                'cv_stability': cv_stability,
                'complexity_score': complexity_score,
                'composite_score': composite_score
            })
            
            print(f"\nğŸ”§ {name} ({model_info['params']}):")
            print(f"   è®­ç»ƒ RÂ²: {train_r2:.4f}")
            print(f"   äº¤å‰éªŒè¯ RÂ²: {cv_r2:.4f} Â± {cv_std:.4f}")
            print(f"   è¿‡æ‹Ÿåˆç¨‹åº¦: {overfitting:.4f}")
            print(f"   æ³›åŒ–æ¯”ç‡: {generalization_ratio:.4f} (è¶Šæ¥è¿‘1è¶Šå¥½)")
            print(f"   CVç¨³å®šæ€§: {cv_stability:.4f} (è¶Šå°è¶Šç¨³å®š)")
            print(f"   ç»¼åˆè¯„åˆ†: {composite_score:.4f}")
            
        except Exception as e:
            print(f"âŒ {name} æ¨¡å‹å¤±è´¥: {e}")
            continue
    
    if not results:
        return None
    
    # åˆ†æç»“æœ
    results_df = pd.DataFrame(results)
    
    print(f"\nğŸ“Š æ¨¡å‹æ’ååˆ†æ:")
    print("="*60)
    
    # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
    results_sorted = results_df.sort_values('composite_score', ascending=False)
    
    for i, (_, row) in enumerate(results_sorted.iterrows(), 1):
        model_type = "å¤æ‚æ¨¡å‹" if row['is_complex'] else "ç®€å•æ¨¡å‹"
        print(f"{i}. {row['model']} ({model_type})")
        print(f"   ç»¼åˆè¯„åˆ†: {row['composite_score']:.4f}")
        print(f"   äº¤å‰éªŒè¯RÂ²: {row['cv_r2']:.4f}")
        print(f"   è¿‡æ‹Ÿåˆç¨‹åº¦: {row['overfitting']:.4f}")
        print(f"   æ³›åŒ–æ¯”ç‡: {row['generalization_ratio']:.4f}")
    
    # å…³é”®åˆ†æï¼šä¸ºä»€ä¹ˆç®€å•æ¨¡å‹å¯èƒ½æ›´å¥½ï¼Ÿ
    simple_models = results_df[~results_df['is_complex']]
    complex_models = results_df[results_df['is_complex']]
    
    if len(simple_models) > 0 and len(complex_models) > 0:
        print(f"\nğŸ¯ å…³é”®å‘ç° - ä¸ºä»€ä¹ˆé€‰æ‹©ç®€å•æ¨¡å‹:")
        print("="*60)
        
        # å¹³å‡æ³›åŒ–èƒ½åŠ›æ¯”è¾ƒ
        simple_avg_gen = simple_models['generalization_ratio'].mean()
        complex_avg_gen = complex_models['generalization_ratio'].mean()
        
        print(f"ğŸ“ˆ å¹³å‡æ³›åŒ–æ¯”ç‡:")
        print(f"   ç®€å•æ¨¡å‹: {simple_avg_gen:.4f}")
        print(f"   å¤æ‚æ¨¡å‹: {complex_avg_gen:.4f}")
        print(f"   å·®å¼‚: {simple_avg_gen - complex_avg_gen:.4f}")
        
        # è¿‡æ‹Ÿåˆæ¯”è¾ƒ
        simple_avg_overfit = simple_models['overfitting'].mean()
        complex_avg_overfit = complex_models['overfitting'].mean()
        
        print(f"\nâš ï¸ å¹³å‡è¿‡æ‹Ÿåˆç¨‹åº¦:")
        print(f"   ç®€å•æ¨¡å‹: {simple_avg_overfit:.4f}")
        print(f"   å¤æ‚æ¨¡å‹: {complex_avg_overfit:.4f}")
        print(f"   å·®å¼‚: {complex_avg_overfit - simple_avg_overfit:.4f}")
        
        # ç¨³å®šæ€§æ¯”è¾ƒ
        simple_avg_stability = simple_models['cv_stability'].mean()
        complex_avg_stability = complex_models['cv_stability'].mean()
        
        print(f"\nğŸ¯ å¹³å‡CVç¨³å®šæ€§ (è¶Šå°è¶Šå¥½):")
        print(f"   ç®€å•æ¨¡å‹: {simple_avg_stability:.4f}")
        print(f"   å¤æ‚æ¨¡å‹: {complex_avg_stability:.4f}")
        
        # æ€»ç»“æ¨è
        best_model = results_sorted.iloc[0]
        print(f"\nğŸ† æ¨èæ¨¡å‹: {best_model['model']}")
        print(f"   ç†ç”±: ç»¼åˆè¯„åˆ†æœ€é«˜ ({best_model['composite_score']:.4f})")
        print(f"   ä¼˜åŠ¿: äº¤å‰éªŒè¯RÂ²={best_model['cv_r2']:.4f}, è¿‡æ‹Ÿåˆ={best_model['overfitting']:.4f}")
    
    return results_df, pearson_r

def analyze_key_relationships():
    """åˆ†æå‡ ä¸ªå…³é”®çš„ç‰¹å¾-æ€§èƒ½å…³ç³»"""
    
    # åŠ è½½æ•°æ®
    data_file = "/home/ubuntu/project/MSC/Msc_Project/models/input_1-100/merged_dataset.csv"
    
    try:
        df = pd.read_csv(data_file)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} è¡Œ")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return
    
    # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§çš„å…³ç³»è¿›è¡Œæ·±å…¥åˆ†æ
    key_relationships = [
        ('cs_density_std', 'charging_time_mean'),
        ('cluster_count', 'charging_station_coverage'),
        ('max_gap_distance', 'energy_gini'),
        ('coverage_ratio', 'vehicle_gini')
    ]
    
    all_results = []
    
    for feature, target in key_relationships:
        if feature in df.columns and target in df.columns:
            result = comprehensive_model_comparison(
                df[feature].values, 
                df[target].values, 
                feature, 
                target
            )
            if result is not None:
                results_df, pearson_r = result
                results_df['feature'] = feature
                results_df['target'] = target
                results_df['pearson_r'] = pearson_r
                all_results.append(results_df)
    
    if all_results:
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        combined_results = pd.concat(all_results, ignore_index=True)
        
        # ä¿å­˜è¯¦ç»†ç»“æœ
        output_file = "/home/ubuntu/project/MSC/Msc_Project/models/detailed_model_comparison.csv"
        combined_results.to_csv(output_file, index=False)
        
        print(f"\nğŸ“‹ æ€»ä½“åˆ†æç»“æœ:")
        print("="*80)
        
        # æŒ‰æ¨¡å‹ç±»å‹æ±‡æ€»
        summary = combined_results.groupby('model').agg({
            'cv_r2': ['mean', 'std', 'count'],
            'overfitting': ['mean', 'std'],
            'generalization_ratio': ['mean', 'std'],
            'composite_score': ['mean', 'std']
        }).round(4)
        
        print("å¹³å‡è¡¨ç°æ±‡æ€»:")
        print(summary)
        
        # å…³é”®ç»“è®º
        simple_performance = combined_results[~combined_results['is_complex']]['composite_score'].mean()
        complex_performance = combined_results[combined_results['is_complex']]['composite_score'].mean()
        
        print(f"\nğŸ¯ å…³é”®ç»“è®º:")
        print(f"ğŸ“Š ç®€å•æ¨¡å‹å¹³å‡ç»¼åˆè¯„åˆ†: {simple_performance:.4f}")
        print(f"ğŸ”§ å¤æ‚æ¨¡å‹å¹³å‡ç»¼åˆè¯„åˆ†: {complex_performance:.4f}")
        
        if simple_performance > complex_performance:
            print(f"âœ… ç»“è®º: ç®€å•æ¨¡å‹æ€»ä½“è¡¨ç°æ›´å¥½ (ä¼˜åŠ¿: {simple_performance - complex_performance:.4f})")
            print(f"ğŸ“ åŸå› : åœ¨å°æ ·æœ¬æ•°æ®ä¸­ï¼Œç®€å•æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›æ›´å¼ºï¼Œè¿‡æ‹Ÿåˆé£é™©æ›´ä½")
        else:
            print(f"âš ï¸ ç»“è®º: å¤æ‚æ¨¡å‹è¡¨ç°ç•¥å¥½ï¼Œä½†éœ€è¦è€ƒè™‘è§£é‡Šæ€§å’Œç¨³å®šæ€§")
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœä¿å­˜è‡³: {output_file}")

if __name__ == '__main__':
    analyze_key_relationships()
